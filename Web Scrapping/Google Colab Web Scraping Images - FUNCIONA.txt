Search :  google colab web scraping images

https://colab.research.google.com/github/joedockrill/image-scraper/blob/master/ImageScraper.ipynb#scrollTo=EYwHbopFG63A

Otra alternativa, tutorial de web scapping con google colab
https://colab.research.google.com/github/nestauk/im-tutorials/blob/3-ysi-tutorial/notebooks/Web-Scraping/Web%20Scraping%20Tutorial.ipynb


!pip install -q jmd_imagescraper


# DELETE ALL IMAGES
rmtree(root)


# Download images
from pathlib import Path
root = Path().cwd()/"images"

from jmd_imagescraper.core import * 
duckduckgo_search(root, "Dogs", "cute puppies", max_results=10)

images = []
images.extend(duckduckgo_search(root, "Dogs", "cute puppies", max_results=10))
images


# Display images
from jmd_imagescraper.imagecleaner import *
display_image_cleaner(root)


# create zip

ZIP_NAME = "images.zip" # maybe change this?

!rm -f {ZIP_NAME}
!zip -q -r {ZIP_NAME} {root}
from google.colab import files
files.download(ZIP_NAME)


# Copy to google drive (if you want)

from google.colab import drive
import shutil

DESTINATION_FOLDER = "Datasets" # where would you like this in Google Drive?

drive.mount("/content/drive") 
folder = Path("/content/drive/My Drive")/DESTINATION_FOLDER
folder.mkdir(parents=True, exist_ok=True)

shutil.copyfile(ZIP_NAME, str(folder/ZIP_NAME))


# If you'd rather distribute a file with the image URLs 

CSV_NAME = "images.csv" # maybe change this?

!rm -f {CSV_NAME}

csv = Path.cwd()/CSV_NAME
save_urls_to_csv(csv, "Dogs", "cute puppies", max_results=5)



You can see the images in Google Colab in
Images/Dogs/


