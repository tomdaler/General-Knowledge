
VERDADERO
¿Respeta Scrapy el archivo robots.txt de un sitio web?
La palabra clave “yield”, ¿le da cualidades de generador a un método de tipo parse?


FALSO
Cuando ejecutamos más de una vez un spider, ¿Scrapy reescribe los archivos de resultados anteriores?
¿El anterior enunciado es?
El método parse permite configurar un spider.


¿Cuál es el atributo dentro de un spider que lo identifica de manera única frente al resto de spiders?
name

¿Cuál de las siguientes configuraciones permite cambiar mi identidad en una petición http?
USER_AGENT

¿Cuál es el formato más eficiente que Scrapy te permite usar para guardar datos que te servirán para nutrir de información a una aplicación web?
JSON

¿Cuál es el formato más eficiente que Scrapy te permite usar para guardar datos que te servirán para realizar tareas de Data Science o análisis de información?
X JSON

¿Cuál es el comando para lanzar la consola de Scrapy?
X scrapy terminal

Dentro de la consola de Scrapy, ¿qué comando nos permite ver las cabeceras de una respuesta http?
X headers

Dentro de la consola de Scrapy, ¿qué comando nos permite ver el método de una petición http?
X request.get

El archivo que contiene información sobre el deployment de nuestro proyecto es:
scrapy.cfg

El atributo que permite controlar si se respeta o no el archivo robots.txt de un sitio web es:
X ROBOTSTXT_RESPECT

El flag que permite guardar un archivo de resultados por consola es:
X -v

El método que permite “seguir” un link dentro de un spider es:
X response.drive

El flag que permite pasar argumentos por consola a un spider es:
X -v

¿En qué carpeta se deben guardar los spiders que creamos?
X scrapy

¿El comando para correr un Spider es?
scrapy start

¿El comando para crear un proyecto de Scrapy es?
scrapy make project

La función que transforma a un iterable en un iterador es:
X next

La función que extrae el siguiente dato de un iterador es:
X extract

Para extraer el texto de todas las etiquetas de tipo “a” en un sitio web puedo utilizar la siguiente expresión de XPath:
X /a/text()

Para extraer todos los nodos span cuya clase es igual a “tag-item” puedo utilizar la siguiente expresión de XPath:
X //span/@class["tag-item"]

¿Para qué debemos instalar Scrapy dentro de un entorno virtual?
X Para poder instalar el framework a nivel global en nuestro equipo.

Que Scrapy sea un framework asíncrono quiere decir que:
No necesita esperar a que termine una petición http para realizar la siguiente.

¿Qué tipos de datos son iterables en Python?
X float, bool, list, set

¿Qué es un generador?
X Una clase de Python que permite generar un iterador al instanciarla.

Scrapy, ¿es un framework de?
x Backend

¿Qué son los spiders?
X Funciones de Python que permiten aplicar XPath a una respuesta http.

Un nodo div con una clase que contiene “tags-box” en su contenido se selecciona mediante la siguiente expresión de XPath:
X //div[starts-with(@class, "tags-box")]


