
https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning

UNDERFIT : HIGH BIAS
- HIGH TRAINING ERROR
- HIGH TEST ERROR


OVERFIT: HIGH VARIANCE
- LOW TRAINING ERROR (BUEN TRAIN FIT)
- HIGH TEST ERROR    (BAD TEST)


How to Prevent Overfitting or Underfitting

Cross-validation: ...
Train with more data. ...
Data augmentation. ...
Reduce Complexity or Data Simplification. ...
Ensembling. ...
Early Stopping. ...
You need to add regularization in case of Linear and SVM models.
In decision tree models you can reduce the maximum depth.



