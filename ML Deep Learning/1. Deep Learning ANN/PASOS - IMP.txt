1) EXPLORE DATOS
- Tipos de datos
	df.dtypes

- Si valores numericos no son string
      df1 = df[df.TotalCharges!=' ']

- Explorar por tipo
      df1[df1.Churn=='No']

- Visualizar si hay regression, correlacion
- Explorar todas las columnas con descr

1.2 Valores unicos
   df1.gender.unique()

1.3 Visualizar con scatter, barras, boxplot

tenure_churn_no = df1[df1.Churn=='No'].tenure
tenure_churn_yes = df1[df1.Churn=='Yes'].tenure

plt.xlabel("tenure")
plt.ylabel("Number Of Customers")
plt.title("TITLE")
plt.hist([tenure_yes, tenure_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])
plt.legend()

1.4  Si hay desbalance

Desvalance, en campo churn
df.Churn.value_counts()

Output
   No     5174  (73% es No)
   Yes    1869




2) LIMPIEZA DE DATOS
- Manejo de outliers

- Manejo de nulls

- Cambiar a tipo numerico
        df.TotalCharges.values
        df.TotalCharges = pd.to_numeric(df1.TotalCharges)


- Elimine columnas sin relevancia (nombre, direccion)
	df.drop('customerID',axis='columns',inplace=True)

- ELimine nulos o asigne promedio
	pd.to_numeric(df.TotalCharges,errors='coerce').isnull()
        df[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]

- Genere categorias, agrupe

Convert Yes / No to 1, 0
yes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',
                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']
for col in yes_no_columns:
    df1[col].replace({'Yes': 1,'No': 0},inplace=True)


df1['gender'].replace({'Female':1,'Male':0},inplace=True)


3) ELIMINAR COLUMNAS, VER RELEVANCIA
- PCA 
- COVARIANZA


4) NORMALIZA
- SCALE FEATURES

cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])


- SI TARGET ES CATEGORICO -> DUMMIE

df2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])
df2.columns


5) SPLIT ENTRE TRAIN / TEST

X = df2.drop('Churn',axis='columns')
y = testLabels = df2.Churn.astype(np.float32)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)


6) ENTRENAMIENTO Y VERIFIQUE EXACTITUD
- Optimizador adam / rmsprop
- Learning rate
- Call back, si llega a alto nivel de exactitud no siga

print(model.evaluate(X_test, y_test))


7) DESPUES SE HACE PREDICCION USANDO X_TEST

y_preds = model.predict(X_test)
y_preds = np.round(y_preds)   #si es binario o 0, 1


8) EL RESULTADO SE COMPARA CON Y_TEST 


9) SI SON POCOS FEATURES SE USA MATRIZ DE CONFUSION


10) SI LA EXACTITUD FUE BUENA EN TRAINING Y MALA EN TEST -> OVERFITTING

LA SOLUCIONES: REGULARIZADORES
- DROPOUT : % QUE DESACTIVA NEURONAS EN CADA LAYER RANDOMLY EN CADA CORRIDA
- L1, L2

