A problem with learned features is that they can be too specialized to the training data, 
or overfit, and not generalize well to new examples. 
Large values in the learned representation can be a sign of the representation being overfit. 


DROPOUT
Simple way to prevent Neural Networks from overfitting
Disable a percentage of neurons on each run


FLATTEN
Matrix -> vector
Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. 
We flatten the output of the convolutional layers to create a single long feature vector. 
And it is connected to the final classification model, which is called a fully-connected layer.


REGULARIZERS
Activity or representation regularization provides a technique to encourage the learned representations, 
the output or activation of the hidden layer or layers of the network, to stay small and sparse.



