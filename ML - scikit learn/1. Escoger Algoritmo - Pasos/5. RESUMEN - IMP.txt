Redes Neurales
==============
Neural networks are best for situations where the data is “high-dimensional.” 
For example, a medium-size image file may have 1024 x 768 pixels. 
Each pixel contains 3 values for the intensity of red, green, and blue at that point in the image. 
All told, this is 1024 x 768 x 3 = 2,359,296 values
Toma mas tiempo pero con mejor exactitud


No supervisado, para clasificar
Primero explora grafico para evaluar algoritmo a usar
Si K-means, SVM, BBScan o Spectral
Usar Dendrograma


K-means, SVM  *****
============
No supervisado
Para Clasificar, ver si hay clusters
SVM tambien sirve para regresion que genera clusters 
Una vez clasificado se actualiza data y se hace KNN

SVM - KNN
- SVM take cares of outliers better than KNN.
- If training data is much larger than no. of features(m>>n), KNN is better than SVM. 
- SVM outperforms KNN when there are large features and lesser training data.


KNN
===
Supervisado
Con dataset ya sabes los clusters
No-parametrico
Clasificacion y regresion

Pero hay un punto de consultar que esta entre varios clusters
Y el algoritmo busca cual cluster es mas cercano


Arbol Decision - Random Forest
==============================
Supervisado
Output categorico, discrite
Cancer maligno, benigno / tipo de flor / se da credito o no
Los features preferibles categorias de Si y No
Soportan no linealidad, se usa cuando no se puede aplicar Regresion Lineal


Random Forest
=============
Inicie con arbol de decision, y luego con Random Forest
Random Forest needs no feature scaling whereas NN needs features to be scaled

Random Forest es crear varios arboles de decision con la misma data 
   y luego evaluar entre los outputs generdos, como votacion



Naive Bayse  ****
===========
Supervisado
Output probabilidad 
-> Small training data set
-> Better for few features
-> Features mutually independent, verifica con covarianza
-> Avoud features correlated
For: Analisis de sentimiento, spam filtering, recommendations, text analysis
Select Gaussian or Mutimodal distribution
-> If it is not possible try random forest.

With a huge feature list, the model may not be accurate, due to the likelihood
would be distributed and may not follow Gaussian nor Multimodal distribution

Naive Bayes with others
-----------------------
- NB when featurs are independent

- NB is a generative model whereas LR is a discriminative model
- NB works well with small datasets, whereas LR+regularization can achieve similar performance.
- LR performs better than NB upon colinearity, as NB expects all features to be independent

- NB is much faster than KNN due to KNN’s real-time execution.
- NB is parametric whereas KNN is non-parametric.

- SVM is a discriminative model whereas NB is generative model

- Decision tree: features are categoricals, discrete
- KNN (supervised) when looking for classification or regression value


NB VS RF
--------
NB model size IS LOW and quite constant the data
NB cannot represent complex behavior, it will get into over fitting

RF model size is VERY LARGE
When data keeps changing

NB can adapt quickly to the changes and new data 
while using a RF you would have to rebuild the forest every time something changes.


SVM vs Naive Bayes :
-------------------
•	Both performs better with low amount of training data and large features.
•	If features are mutually dependent, SVM outperforms Naive Bayes.
•	SVM is a discriminative model whereas NB is generative model.


Series de tiempo
Supervisado
Tendencia, Season, Noise


Regresion 
=========
Supervisado
Output: CONTINUO (en arbol de decision, logistica es categorico)
Explore primero si data tiene regresion o correlacion entre variables
Lineal o no lineal
Una variable o multivariables
Asume que error (residuales) generados seran random distributed
-> No maneja bien outliers, debe eliminarlos antes de utilizarlo

LR vs Neural Networks :
•	NN need large training data compared to LR model, whereas LR can work well even with less training data.
•	NN will be slow compared to LR.
•	Average accuracy will be always better with neural networks.

LR performs better than naive bayes upon colinearity, as naive bayes expects all features to be independent.
LR can handle better colinearidad, NB espera que todos los features sean independientes <---


Logistica 
=========
Supervisado
Ouput: DISCRETO, CATEGORIAS <---
Explore primero si data tiene regresion o correlacion entre variables
Si una variable: agregue SVM
Si tiene 4 outputs, agregue matriz confusion
Para soluciones lineales <-- es decir, x1, x2, x3 influyen en Y directamente.


IMPORTANTE
==========
- Regresion Lineal: Y, target, continuo (Y LINEAL)
- Regresion logistica: Y, target, discreto, categorias

CUANDO EL OUTPUT ES DE 4 CATEGORIAS 
-> MATRIZ CONFUSION
-> SVM

